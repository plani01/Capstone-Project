{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07aa3ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split# !Figure out how to put seed \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix #! need to reserach this again, make notes\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from PIL import Image, ImageDraw\n",
    "import xml.etree.ElementTree as ET # reads xml bounding box annotation, used for create labels matrix function \n",
    "#import cv2 # maybe need it later for visualization, Image for bounding box is good now, also matplot for simple(no box)\n",
    "import matplotlib.pyplot as plt    # Not currently used \n",
    "import dill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eb4edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Suggestion for testing: don't have to resize necesarily or even decrease more, keep base resolution, prob more accurate\"\"\"\n",
    "def Create_Data_Matrix(directory):\n",
    "    i=0\n",
    "    for file in os.listdir(directory):\n",
    "        filename = directory+'/'+file\n",
    "\n",
    "        # Loads image, converts to grayscale and resizes it to a 300x300 image\n",
    "        y = np.array(Image.open(filename).convert('RGB').resize((300,300)))\n",
    "\n",
    "        # Resizes 300x300 image to 90,000x1 array\n",
    "        col_y = y.ravel()[:,np.newaxis]\n",
    "\n",
    "        # Saves\n",
    "        if i==0:\n",
    "            data = col_y\n",
    "        else:\n",
    "            data = np.hstack((data, col_y))\n",
    "\n",
    "        # Plots image\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(5,5))\n",
    "        plt.imshow(y, cmap='gray')\n",
    "        plt.xticks([]),plt.yticks([])\n",
    "        plt.show();\n",
    "        \"\"\"\n",
    "        i+=1\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88da934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Labels_Matrix(directory):\n",
    "    i=0\n",
    "    for file in os.listdir(directory):\n",
    "        filename = directory+'/'+file\n",
    "        tree = ET.parse(filename)\n",
    "        root = tree.getroot()\n",
    "        sample_annotations = []\n",
    "        for neighbor in root.iter('bndbox'):\n",
    "            xmin = int(neighbor.find('xmin').text)\n",
    "            ymin = int(neighbor.find('ymin').text)\n",
    "            xmax = int(neighbor.find('xmax').text)\n",
    "            ymax = int(neighbor.find('ymax').text)\n",
    "            sample_annotations.append([xmin, ymin, xmax, ymax])\n",
    "            if i==0:\n",
    "                data = sample_annotations\n",
    "            else:\n",
    "                data = np.vstack((data, sample_annotations))\n",
    "            break;\n",
    "        i+=1\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b50ec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Creating the data matrix\"\"\"\n",
    "\n",
    "#!! Suggestion: extra pictures later in dimmed light: this is critical for extra accuracy \n",
    "\n",
    "#using absolute paths in order to save OneDrive Space (don't want it to just fill with training pics)\n",
    "bottleCap_pics=r\"C:/Users/plani/Documents/Design2 Pics/cap/imgs\"\n",
    "bottleCap_labels=r\"C:/Users/plani/Documents/Design2 Pics/cap/labels\"\n",
    "\n",
    "lighter_pics=r\"C:/Users/plani/Documents/Design 1/ML repo/copy/MachineLearning/ML pics/Lighter\"\n",
    "lighter_labels=r\"C:/Users/plani/Documents/Design2 Pics/lighter/labels\"\n",
    "\n",
    "emptyClass_pics = r\"C:/Users/plani/Documents/Design2 Pics/empty\"\n",
    "\n",
    "bottleCap_array = Create_Data_Matrix(bottleCap_pics)\n",
    "lighter_array = Create_Data_Matrix(lighter_pics)\n",
    "emptyClass_array = Create_Data_Matrix(emptyClass_pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d6ed1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleCap_boxArray = Create_Labels_Matrix(bottleCap_labels)\n",
    "lighter_boxArray = Create_Labels_Matrix(lighter_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "474dbe96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bottle cap array size: (270000, 133)\n",
      "lighter array size: (270000, 276)\n",
      "empty class array size (270000, 67)\n",
      "bottle cap label array size: (133, 4)\n",
      "lighter label array size: (276, 4)\n"
     ]
    }
   ],
   "source": [
    "# 133 bottle cap images, each img rescaled to 300x300 and ravel() called = 90k. Since each pixel has 3 channels RGB, it is\n",
    "# 90k * 3 = 270k\n",
    "\n",
    "print(\"bottle cap array size:\",bottleCap_array.shape)\n",
    "print(\"lighter array size:\",lighter_array.shape)\n",
    "print(\"empty class array size\",emptyClass_array.shape)\n",
    "\n",
    "print(\"bottle cap label array size:\",bottleCap_boxArray.shape)\n",
    "print(\"lighter label array size:\",lighter_boxArray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7143833e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((409, 270000), (409, 4))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"X: Feature Matrix for Regression, t: TARGET MATRIX \"\"\"\n",
    "X = np.hstack((bottleCap_array, lighter_array)).T\n",
    "X = X/255.\n",
    "\n",
    "t = np.vstack((bottleCap_boxArray, lighter_boxArray))\n",
    "\n",
    "X.shape, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0a78a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((327, 270000), (82, 270000))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class_id used for stratified train/test split\n",
    "class_id = np.hstack((np.ones(133), 2*np.ones(276))) \n",
    "X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.2, random_state=42, stratify=class_id)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e0f7690",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model Definition\"\"\"\n",
    "model = SVR(kernel='rbf', C=1E9, epsilon=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3cb59810",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SVR Model Training\"\"\"\n",
    "# cannot do model.fit(x_train, t_train) because t_train is a multivariable\n",
    "# output (4 coordinates)\n",
    "multi_model = MultiOutputRegressor(model).fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "60212d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"STORE MODEL\"\"\"\n",
    "# store the model using the 'dill library, dill apparently \"serializes \n",
    "#  better than pickle\" \n",
    "dill_filename = \"SVM_regress.pkl\"\n",
    "with open(dill_filename, 'wb') as file:\n",
    "    dill.dump(multi_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d957baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SVR Model Prediction\"\"\"\n",
    "y_train = multi_model.predict(X_train)\n",
    "y_test = multi_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "52aaa02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2382.50011187,  592.50012481, 2608.50008751,  760.50004057],\n",
       "       [2367.49998094, 1103.49986472, 2652.50009358, 1293.50004269],\n",
       "       [1184.50038157, 2680.50015724, 1790.49984316, 3271.50012385],\n",
       "       ...,\n",
       "       [2184.49999519,  963.49970162, 2528.50026975, 1285.49996106],\n",
       "       [ 849.50007641,  197.50032829, 1207.50001738,  380.50058386],\n",
       "       [1316.50005307,  716.49971267, 1791.49970665,  950.49981945]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_copy = y_train\n",
    "y_train_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e21f8acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1161.        ,  896.67350013],\n",
       "       [2542.        , 1893.30221435],\n",
       "       [  12.        ,  523.70663811],\n",
       "       [ 694.        ,  785.6377801 ],\n",
       "       [1746.        , 1559.37761782],\n",
       "       [2219.        , 1642.82764506],\n",
       "       [1227.        , 1346.07967776],\n",
       "       [1373.        ,  946.02353528],\n",
       "       [ 365.        , 1133.69659632],\n",
       "       [1966.        , 1857.07681945],\n",
       "       [ 168.        , 1097.36020976],\n",
       "       [2104.        , 1960.25831169]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col1 = np.array(t_test[0:12,1])[:,np.newaxis]\n",
    "col2 = np.array(y_test[0:12,1])[:, np.newaxis]\n",
    "\n",
    "cols = np.hstack((col1,col2))\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a3bf99a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([299.69346936, 300.13675252, 314.29503114, 379.13225026])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"SVR Test Performace, shows 300 pixels off\"\"\"\n",
    "score_abs = mean_absolute_error(t_test, y_test, multioutput='raw_values')\n",
    "score_abs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c6fa94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50000734, 0.50000316, 0.50002107, 0.49866465])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"SVR Training Performance, only shows 0.5 pixel value discrepancy\"\"\"\n",
    "score_abs = mean_absolute_error(t_train, y_train, multioutput='raw_values')\n",
    "score_abs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
